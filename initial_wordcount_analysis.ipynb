{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get all files in the \"by reviewer\" directory\n",
      "#then, for each file, find the most common words\n",
      "#find the most common words, if the stopwords are taken out.\n",
      "#find the most common words belonging to certain schemas\n",
      "\n",
      "#imports\n",
      "import os\n",
      "\n",
      "reviewerdir = os.getcwd() + '/reviewerdata/'\n",
      "criticfiles = os.listdir(reviewerdir)\n",
      "\n",
      "#a lot of this analysis will be centered around this reviewer.\n",
      "target = reviewerdir + 'reviewers9'\n",
      "print target"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/sidharth/Documents/sem_spr_14_15/jp/initial_code/reviewerdata/reviewers9\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get all the text of the review in this function.\n",
      "targetfile = open(target, \"r\")\n",
      "storenext = 0\n",
      "alltext = \"\"\n",
      "for line in targetfile:\n",
      "    #this warns us that the next line is the title or author name; therefore we shouldn't store it.\n",
      "    if (line == \"Title\\n\") or (line == \"Authors\\n\") or (line == \"Number of Reviews\\n\"):\n",
      "        storenext = 0\n",
      "    elif storenext == 0:\n",
      "        storenext = 1\n",
      "    else:\n",
      "        alltext += line\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk.probability import FreqDist\n",
      "from nltk.corpus import stopwords\n",
      "\n",
      "#set up the freqDist object; counts all tokens that appear in these reviews.\n",
      "allfiles_freq = FreqDist()\n",
      "for sent in nltk.tokenize.sent_tokenize(alltext):\n",
      "    for word in nltk.tokenize.word_tokenize(sent):\n",
      "        #takes out faulty tokens like \"n't\", and stopwords\n",
      "        if word.isalpha() and not (word.lower() in stopwords.words('english')):\n",
      "            allfiles_freq.inc(word)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print out all the words not classified as stop-words.\n",
      "allfiles_freq.plot(100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#repeat the analysis shown before, with about 20 different prolific reviewers\n",
      "\n",
      "#Set up the analysis with the new file\n",
      "#TARGET IS DEFINED IN THE FIRST BOX\n",
      "target = reviewerdir + 'reviewers108'\n",
      "\n",
      "#get all the text of the reviews in this function.\n",
      "targetfile = open(target, \"r\")\n",
      "storenext = 0\n",
      "alltext = \"\"\n",
      "for line in targetfile:\n",
      "    #this warns us that the next line is the title or author name; therefore we shouldn't store it.\n",
      "    if (line == \"Title\\n\") or (line == \"Authors\\n\") or (line == \"Number of Reviews\\n\"):\n",
      "        storenext = 0\n",
      "    elif storenext == 0:\n",
      "        storenext = 1\n",
      "    else:\n",
      "        alltext += line\n",
      "\n",
      "#set up the freqDist object; counts all tokens that appear in these reviews.\n",
      "allfiles_freq = FreqDist()\n",
      "for sent in nltk.tokenize.sent_tokenize(alltext):\n",
      "    for word in nltk.tokenize.word_tokenize(sent):\n",
      "        #takes out faulty tokens like \"n't\", and stopwords\n",
      "        if word.isalpha() and not (word.lower() in stopwords.words('english')):\n",
      "            allfiles_freq.inc(word)\n",
      "            \n",
      "#print out all the words not classified as stop-words.\n",
      "allfiles_freq.plot(50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    }
   ],
   "metadata": {}
  }
 ]
}