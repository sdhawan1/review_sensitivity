{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Algorithm to find sentiment-words of an author.\n",
      "\n",
      "#A POSSIBLY EQUIVALENT WAY TO DO ALL OF THIS: USE LDA TO FIND TOPICS WITHIN REVIEWS. THEN PERFORM THIS ANALYSIS\n",
      "#ON THE TOPICS FOUND BY THAT ALGORITHM. SHOULD TRY THAT AT SOME POINT!!!\n",
      "\n",
      "#fastest way to do it: first, refine your set of useful words: i.e. add all words in the synsets of your given words\n",
      "# to the set of useful words. For example, \"believable\" should match \"believability\"\n",
      "#[AND / OR: JUST CALCULATE WITH REGEXPS WHILE SEARCHING?]\n",
      "\n",
      "#second, before we start looking at an author, create an initial FreqDist with those words (one for df, one for tf).\n",
      "#third, fill in the frequency of words in the document and in all documents.\n",
      "\n",
      "#fourth, figure out the sentiment stuff. That's going to get ugly... I think possibly the best way to do it is to\n",
      "# tokenize sentences, get their sentiment, and for each word (i.e. token) in the sentence, try to add it to some\n",
      "# item in the FreqDist. If there isn't an entry for your word, do nothing.\n",
      "\n",
      "\n",
      "#create a freqdist object for all the best words (so far)\n",
      "\n",
      "## WORDS TO ADD: inspiring/inspired, practical & plausible, sexism, sexist, bigot, offensive, politically_correct?\n",
      "from nltk.probability import FreqDist\n",
      "import nltk\n",
      "\n",
      "ctr = 0\n",
      "f = open(\"freq_topic_words_mod\")\n",
      "words = \"\"\n",
      "for line in f:\n",
      "    ctr += 1\n",
      "    if ctr > 392:\n",
      "        break\n",
      "    linearr = line.split()\n",
      "    words += (\" \"+linearr[0])\n",
      "    \n",
      "topic_fd = FreqDist(nltk.word_tokenize(words))\n",
      "\n",
      "#get the indices of all reviewers with between 10 and 200 reviewes.\n",
      "f = open(\"generated_data/revspercritic\", \"r\")\n",
      "index = 0\n",
      "rev_inds = []\n",
      "for line in f:\n",
      "    index += 1\n",
      "    numrevs = int(line)\n",
      "    if (numrevs >= 10) and (numrevs <= 200):\n",
      "        rev_inds = rev_inds + [index]\n",
      "        \n",
      "#print rev_inds\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#EVENTUALLY, THIS STEP SHOULD BE REPEATED FOR EVERY REVIEWER IN THE INDEX CREATED ABOVE.\n",
      "#WE STILL NEED TO INCORPORATE CALCULATION OF SENTIMENT.\n",
      "#NOTE: THIS IS A MUCH FASTER WAY TO PROCESS TEXT THAT WHAT I WAS DOING BEFORE.\n",
      "\n",
      "#experiments with reviewer 8: figure out his term frequency and document frequency for every word.\n",
      "\n",
      "\n",
      "#first, isolate his reviews: put them in a big list.\n",
      "import os\n",
      "from nltk.corpus import stopwords\n",
      "\n",
      "#setup freqdist objects\n",
      "termfreq = FreqDist(nltk.word_tokenize(words))\n",
      "docfreq = FreqDist(nltk.word_tokenize(words))\n",
      "topic_keys = topic_fd.keys()\n",
      "sw = stopwords.words(\"english\")\n",
      "\n",
      "target = os.getcwd() + '/reviewerdata/reviewers8'\n",
      "f = open(target)\n",
      "\n",
      "#split the file into its different reviews, save each review as an item in a list.\n",
      "ftxt = f.read()\n",
      "reviews = ftxt.split(\"Title\\n\")\n",
      "for review in reviews:\n",
      "    ## eliminate the first two lines of the review.\n",
      "    revsplit = review.split(\"\\n\")\n",
      "    review = '\\n'.join(revsplit[2:])\n",
      "    ## create freqdist of words; update document frequency and term frequency\n",
      "    review_fd = FreqDist(nltk.word_tokenize(review))    \n",
      "    keys = review_fd.keys()    \n",
      "    \n",
      "    ## incorporate words into freqdists.\n",
      "    keys = [key for key in keys if key in topic_keys]\n",
      "    for key in keys:\n",
      "        docfreq.inc(key)\n",
      "    for key in keys:\n",
      "        termfreq[key] += review_fd[key]\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#take the above procedure and perform it for all reviewers with between 10 and 200 reviews.\n",
      "from nltk.probability import FreqDist\n",
      "import nltk\n",
      "import os\n",
      "\n",
      "ctr = 0\n",
      "f = open(\"freq_topic_words_mod\")\n",
      "words = \"\"\n",
      "for line in f:\n",
      "    ctr += 1\n",
      "    if ctr > 392:\n",
      "        break\n",
      "    linearr = line.split()\n",
      "    words += (\" \"+linearr[0])\n",
      "    \n",
      "topic_fd = FreqDist(nltk.word_tokenize(words))\n",
      "topic_keys = topic_fd.keys()\n",
      "\n",
      "#get the indices of all reviewers with between 10 and 200 reviewers.\n",
      "f = open(\"generated_data/revspercritic\", \"r\")\n",
      "index = 0\n",
      "rev_inds = []\n",
      "for line in f:\n",
      "    index += 1\n",
      "    numrevs = int(line)\n",
      "    if (numrevs >= 10) and (numrevs <= 200):\n",
      "        rev_inds = rev_inds + [index]\n",
      "        \n",
      "for ind in rev_inds:\n",
      "    termfreq = FreqDist(nltk.word_tokenize(words))\n",
      "    docfreq = FreqDist(nltk.word_tokenize(words))\n",
      "    f = open(os.getcwd()+\"/reviewerdata/reviewers\"+str(ind), \"r\")\n",
      "    fres = open(os.getcwd()+\"/reviewerwdscores/tf_df_reviewers\"+str(ind), \"w\")\n",
      "    \n",
      "    #now, process the data\n",
      "    #split the file into its different reviews, save each review as an item in a list.\n",
      "    ftxt = f.read()\n",
      "    reviews = ftxt.split(\"Title\\n\")\n",
      "    for review in reviews:\n",
      "        ## eliminate the first two lines of the review.\n",
      "        revsplit = review.split(\"\\n\")\n",
      "        review = '\\n'.join(revsplit[2:])\n",
      "        ## create freqdist of words; update document frequency and term frequency\n",
      "        review_fd = FreqDist(nltk.word_tokenize(review))    \n",
      "        ## filter out non-stopwords and non-alphabetical\n",
      "        keys = review_fd.keys()    \n",
      "        \n",
      "        ## incorporate words into freqdists.\n",
      "        keys = [key for key in keys if key in topic_keys]\n",
      "        for key in keys:\n",
      "            docfreq.inc(key)\n",
      "        for key in keys:\n",
      "            termfreq[key] += review_fd[key]\n",
      "    \n",
      "    #write output to file\n",
      "    #it goes, word, term freq, then doc freq. We will do emotions separately.\n",
      "    for word in termfreq:\n",
      "        fres.write(word+' '+str(termfreq[word])+' '+str(docfreq[word])+'\\n')\n",
      "    fres.close()\n",
      "    print \"done with %d!\" % ind\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "done with 8!\n",
        "done with 9!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 10!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 12!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 24!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 37!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 47!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 63!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 66!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 71!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 76!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 92!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 94!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 97!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 108!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 115!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 116!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 133!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 137!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 142!\n",
        "done with 145!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 155!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 170!\n",
        "done with 176!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 184!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 185!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 187!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 195!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 216!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 250!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 258!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 261!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 268!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 270!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 291!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 299!\n",
        "done with 302!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 305!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 312!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 329!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 331!\n",
        "done with 333!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 355!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 380!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 405!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 413!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 416!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 417!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 421!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 423!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 436!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 447!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 462!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 465!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 480!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 488!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 490!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 491!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 493!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 496!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 515!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 523!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 535!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 536!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 546!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 563!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 569!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 577!\n",
        "done with 580!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 582!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 592!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 593!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 608!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 619!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 630!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 631!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 648!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 656!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 657!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 658!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 663!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 667!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 674!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 677!\n",
        "done with 684!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 686!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 687!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 693!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 700!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 707!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 716!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 717!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 739!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 754!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 760!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 773!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 777!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 778!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 779!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 781!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 783!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 789!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 794!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 799!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 812!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 814!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 817!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 818!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 827!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 829!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 860!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 864!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 883!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 907!\n",
        "done with 912!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 924!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 926!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 960!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 965!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 975!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 977!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 989!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 993!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1002!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1006!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1008!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1014!\n",
        "done with 1018!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1021!\n",
        "done with 1031!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1045!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1046!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1069!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1082!\n",
        "done with 1100!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1101!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1102!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1110!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1111!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1131!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1140!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1141!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1148!\n",
        "done with 1154!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1158!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1163!\n",
        "done with 1168!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1180!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1184!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1210!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1213!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1216!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1217!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1220!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1232!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1241!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1265!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1278!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1280!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1292!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1301!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1330!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1338!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1339!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1346!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1359!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1368!\n",
        "done with 1385!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1397!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1406!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1426!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1427!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1432!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1438!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1441!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1444!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1460!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1471!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1477!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1479!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1484!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1493!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1501!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1503!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1529!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1540!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1545!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1549!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1560!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1561!\n",
        "done with 1562!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1565!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1566!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1574!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1580!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1583!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1584!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1594!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done with 1597!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## For every reviewer, find the sentiment of every word. FIGURE OUT WAYS TO SPEED UP THIS PROCESS.\n",
      "#maybe first, we sentence-tokenize entire document, and then we word-tokenize for every sentence with a tuple\n",
      "# then do something...\n",
      "# investigate how long each part takes.\n",
      "\n",
      "import nltk\n",
      "import os\n",
      "from senti_classifier import senti_classifier\n",
      "\n",
      "for ind in rev_inds:\n",
      "    #creates a dictionary with one item for every term, matched to a zero initially.\n",
      "    #NOTE: TOPIC_KEYS FROM ABOVE HAS TO BE CREATED!\n",
      "    wd_senti_pos = dict(zip(topic_keys, [0]*len(topic_keys)))\n",
      "    wd_senti_neg = dict(zip(topic_keys, [0]*len(topic_keys)))\n",
      "    \n",
      "    f = open(os.getcwd()+\"/reviewerdata/reviewers\"+str(ind), \"r\")\n",
      "    fres = open(os.getcwd()+\"/reviewerwdscores/senti_reviewers\"+str(ind), \"w\")\n",
      "    \n",
      "    ftxt = f.read()\n",
      "    ftxt = ftxt.replace('\\r\\n', \" \")\n",
      "    ftxt = ftxt.replace(\"\\n\", \". \")\n",
      "    sentences = nltk.sent_tokenize(ftxt)\n",
      "    sent_wds = [(sent, nltk.word_tokenize(sent)) for sent in sentences]\n",
      "    \n",
      "    sent_topicwds = []  \n",
      "    for sent, wds in sent_wds:\n",
      "        topicwds = [wd for wd in wds if wd in topic_keys]\n",
      "        if len(topicwds) > 0:\n",
      "            sent_topicwds += [(sent, topicwds)]\n",
      "    \n",
      "    #now, figure out sentiment.\n",
      "    for sent, wds in sent_topicwds:\n",
      "        pos, neg = senti_classifier.polarity_scores(sent)\n",
      "        for wd in wds:\n",
      "            wd_senti_pos[wd] += pos\n",
      "            wd_senti_neg[wd] += neg\n",
      "    break\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read statistics for each author, and try to cluster using those statistics.\n",
      "## THIS CELL IS JUST DATA PREPARATION. CAN START OFF FROM HERE, BECAUSE THIS READS IN DATA STORED EARLIER.\n",
      "import os\n",
      "import numpy\n",
      "rdfiledir = os.getcwd() + \"/reviewerwdscores/\"\n",
      "rdfiles = os.listdir(rdfiledir)\n",
      "\n",
      "#first, get indices for the review.\n",
      "f = open(\"generated_data/revspercritic\", \"r\")\n",
      "index = 0\n",
      "rev_inds = []\n",
      "for line in f:\n",
      "    index += 1\n",
      "    numrevs = int(line)\n",
      "    if (numrevs >= 10) and (numrevs <= 200):\n",
      "        rev_inds = rev_inds + [index]\n",
      "\n",
      "#first, get all the words and set up proper data structures.\n",
      "#NOTE: 392 words have been approved.\n",
      "f = open(\"freq_topic_words_mod\")\n",
      "i = 0\n",
      "topicwords = []\n",
      "for line in f:\n",
      "    i += 1\n",
      "    if i > 392:\n",
      "        break\n",
      "    linearr = line.split()\n",
      "    topicwords += [linearr[0]]\n",
      "    \n",
      "#this sets up the correct data structure (n-d array) for clustering.    \n",
      "words_freqs = numpy.ndarray((199, 392), dtype = int)\n",
      "\n",
      "\n",
      "#create a dictionary that maps words to their indices.\n",
      "wordtoind = {}\n",
      "for i in range(392):\n",
      "    wordtoind = dict(zip(topicwords, range(392)))\n",
      "\n",
      "#now, populate the n-dimensional array in preparation for clustering\n",
      "nauths = 0\n",
      "for fname in rdfiles:\n",
      "    f = open(rdfiledir + fname, \"r\")\n",
      "    #ftxt = f.read()\n",
      "    for line in f:\n",
      "        linearr = line.split(' ')\n",
      "        wd = linearr[0]\n",
      "        tf = int(linearr[1])\n",
      "        words_freqs[nauths, wordtoind[wd]] = tf\n",
      "    f.close()    \n",
      "    nauths += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#use the results of the above cell to cluster the documents based on their word tf only (for now)\n",
      "\n",
      "#try k-means clustering.\n",
      "from sklearn.cluster import KMeans\n",
      "cls = KMeans(init=\"k-means++\", n_clusters=10)\n",
      "labels = cls.fit_predict(words_freqs)\n",
      "print labels\n",
      "\n",
      "#have to find some way of evaluating information gain here!\n",
      "i = [0]*10\n",
      "for label in labels:\n",
      "    i[label] += 1\n",
      "print i\n",
      "# NOTE: THESE DISTRIBUTIONS ARE MUCH MORE SKEWED THAN WITH THE LDA RESULTS, WHERE THEY WERE CLOSE TO NORMALLY\n",
      "#DISTRIBUTED. (This may be because I didn't scale down the df sizes.)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0 0 0 0 0 0 3 3 3 3 0 0 0 0 0 6 3 0 0 1 0 0 6 1 0 0 6 0 0 3 1 6 3 6 0 3 0\n",
        " 0 0 0 0 3 6 0 0 3 0 0 0 0 6 0 0 0 0 0 6 7 0 0 0 0 6 0 1 0 0 6 6 8 0 0 0 0\n",
        " 8 0 7 0 0 0 6 0 0 3 0 0 3 7 0 0 0 1 0 5 0 0 0 2 0 6 0 7 0 0 0 0 3 0 0 0 0\n",
        " 0 1 1 0 7 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 1 0 6 1 0 0 0 3 0 0 0 0 0 6 0 3 0\n",
        " 0 6 0 0 0 3 0 0 0 0 6 0 0 0 0 7 0 0 6 4 6 6 0 6 0 6 3 0 0 0 0 6 0 0 0 6 6\n",
        " 6 0 0 0 9 6 0 0 0 0 0 1 0 0]\n",
        "[132, 10, 1, 18, 1, 1, 27, 6, 2, 1]\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## NOTE: THIS EVALUATION MAY WORK FOR LDA, BUT IS NOT CURRENTLY TAILORED FOR THE CLUSTERING PERFORMED ABOVE.\n",
      "## EITHER CHANGE THE METRIC ABOVE, OR COME UP WITH SOME OTHER EVALUATION.\n",
      "\n",
      "###### try to evaluate goodness of clustering\n",
      "#[NOTE] relies on creation of \"topicwords\", \"wordtoind\", \"cls\", etc. above!!!\n",
      "import nltk\n",
      "from nltk.probability import FreqDist\n",
      "import numpy\n",
      "from senti_classifier import senti_classifier\n",
      "\n",
      "#first, pick out the movies with the right number of reviews for clustering.\n",
      "f = open(\"generated_data/revspermovie\", \"r\")\n",
      "movinds = []\n",
      "ind = 0\n",
      "for line in f:\n",
      "    numrevs = int(line)\n",
      "    if numrevs > 25:\n",
      "        movinds += [ind]\n",
      "    ind += 1\n",
      "\n",
      "    \n",
      "#TEST: JUST EVALUATE ONE MOVIE FOR NOW\n",
      "#set up correct data structure for plugging into k-means prediction\n",
      "obs = numpy.ndarray((1, 392), dtype = int)\n",
      "\n",
      "movieno = movinds[0]\n",
      "moviefile = open(\"moviedata/movie\" + str(movieno), \"r\")\n",
      "#split the file into its different reviews, save each review as an item in a list.\n",
      "ftxt = moviefile.read()\n",
      "reviews = ftxt.split(\"Author\\n\")\n",
      "i = 0\n",
      "for review in reviews:\n",
      "    if i == 0:\n",
      "        i += 1\n",
      "        continue\n",
      "    ## eliminate the first two lines of the review.\n",
      "    revsplit = review.split(\"\\n\")\n",
      "    review = '\\n'.join(revsplit[1:])\n",
      "    ## create freqdist of words; update document frequency and term frequency\n",
      "    review_fd = FreqDist(nltk.word_tokenize(review))    \n",
      "    ## filter out non-stopwords and non-alphabetical\n",
      "    keys = review_fd.keys()    \n",
      "    \n",
      "    ## incorporate words into freqdists.\n",
      "    keys = [key for key in keys if key in topicwords]\n",
      "    #for key in keys:\n",
      "    #    docfreq.inc(key)\n",
      "    for key in keys:\n",
      "        obs[0,wordtoind[key]] += review_fd[key]\n",
      "    print cls.predict(obs)\n",
      "    print senti_classifier.polarity_scores(review)\n",
      "    \n",
      "    #reset \"obs\"\n",
      "    obs = numpy.ndarray((1, 392), dtype = int)\n",
      "    \n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0]\n",
        "(0.0, 0.0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[0]\n",
        "(0.0, 0.0)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#use this cell for printing and testing.\n",
      "\n",
      "#corrects freqdist bug and tests\n",
      "\"\"\"\n",
      "import nltk\n",
      "topic_fd = FreqDist(nltk.word_tokenize(words))\n",
      "print topic_fd\n",
      "\"\"\"\n",
      "\n",
      "#print topic_fd['believable']\n",
      "\n",
      "#check how well the stemmer works, and group words with common stems together\n",
      "\"\"\"\n",
      "import snowballstemmer\n",
      "stemmer = snowballstemmer.stemmer(\"english\")\n",
      "stems_fd = FreqDist()\n",
      "for key in topic_fd.keys():\n",
      "    stems_fd.inc(stemmer.stemWord(key))\n",
      "print len(stems_fd)\n",
      "for key in stems_fd.keys():\n",
      "    print key + ' ' + str(stems_fd[key])\n",
      "\"\"\"\n",
      "\n",
      "#test: processing data in a file\n",
      "\"\"\"\n",
      "revsplit = reviews[1].split('\\n')\n",
      "print revsplit[1]\n",
      "\"\"\"\n",
      "\n",
      "#print out stats for tf and df\n",
      "\"\"\"\n",
      "print topic_fd\n",
      "print \"TERMFREQ\"\n",
      "print termfreq\n",
      "print \"DOCFREQ\"\n",
      "print docfreq\n",
      "\"\"\"\n",
      "\n",
      "#initial attempt at detecting sentiment - very slow.\n",
      "\"\"\"\n",
      "## now the ugly part - try to figure out sentiment of sentences\n",
      "        sentences = nltk.sent_tokenize(review)\n",
      "        wd_hit = 0\n",
      "        pos = 0\n",
      "        neg = 0\n",
      "        for sent in sentences:\n",
      "            wd_hit = 0\n",
      "            words = nltk.word_tokenize(sent)\n",
      "            for w in words:\n",
      "                if w in wd_senti_pos:\n",
      "                    if not wd_hit:\n",
      "                        wd_hit = 1\n",
      "                        pos, neg = senti_classifier.polarity_scores(sent)\n",
      "                    wd_senti_pos[w] += pos\n",
      "                    wd_senti_neg[w] += neg\n",
      "                else:\n",
      "                    continue\n",
      "\"\"\"\n",
      "\n",
      "#print sent_topicwds\n",
      "\n",
      "#tests to see whether the data got stored in the data structure properly.\n",
      "#print rdfiles\n",
      "print words_freqs[0, wordtoind['dialogue']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\n"
       ]
      }
     ],
     "prompt_number": 16
    }
   ],
   "metadata": {}
  }
 ]
}