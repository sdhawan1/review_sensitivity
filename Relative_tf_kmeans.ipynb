{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#THIS CELL IS LIKE \"PCT_DOCFREQ_CLUSTERS_KMEANS\", except we cluster by tf/total_useful_terms, instead of \n",
      "# by df/total_docs\n",
      "\n",
      "# read statistics for each author, and try to cluster using those statistics.\n",
      "## THIS CELL IS JUST DATA PREPARATION. CAN START OFF FROM HERE, BECAUSE THIS READS IN DATA STORED EARLIER.\n",
      "import os\n",
      "import numpy\n",
      "rdfiledir = os.getcwd() + \"/reviewerwdscores/tf_df_reviewers\"\n",
      "#rdfiles = os.listdir(rdfiledir)\n",
      "\n",
      "#first, get indices for the reviewers, and get their review frequencies.\n",
      "f = open(\"generated_data/revspercritic\", \"r\")\n",
      "index = 0\n",
      "rev_inds = []\n",
      "for line in f:\n",
      "    index += 1\n",
      "    numrevs = int(line)\n",
      "    if (numrevs >= 10) and (numrevs <= 200):\n",
      "        rev_inds = rev_inds + [index]\n",
      "\n",
      "#now, get all the words and set up proper data structures.\n",
      "#NOTE: 392 words and 200 reviewers have been approved.\n",
      "\n",
      "#this collects the on-topic words.\n",
      "f = open(\"freq_topic_words_mod\")\n",
      "i = 0\n",
      "topicwords = []\n",
      "for line in f:\n",
      "    i += 1\n",
      "    if i > 392:\n",
      "        break\n",
      "    linearr = line.split()\n",
      "    topicwords += [linearr[0]]\n",
      "    \n",
      "#this sets up the correct data structure (n-d array) for clustering.    \n",
      "words_freqs = numpy.ndarray((199, 392), dtype = int)\n",
      "#create a dictionary that maps words to their indices.\n",
      "wordtoind = {}\n",
      "for i in range(392):\n",
      "    wordtoind = dict(zip(topicwords, range(392)))\n",
      "\n",
      "#now, populate the n-dimensional array in preparation for clustering\n",
      "#initial parameter: 100*tf/total_terms [this puts all reviews on the same scale.]\n",
      "for i in range(len(rev_inds)):\n",
      "    f = open(rdfiledir + str(rev_inds[i]), \"r\")\n",
      "    #ftxt = f.read()\n",
      "    total_tf = 0\n",
      "    for line in f:\n",
      "        linearr = line.split(' ')\n",
      "        wd = linearr[0]\n",
      "        tf = int(linearr[1])-1\n",
      "        total_tf += tf\n",
      "        words_freqs[i, wordtoind[wd]] = tf\n",
      "        \n",
      "    for j in range(len(words_freqs[i,:])):\n",
      "        tf = words_freqs[i, j]\n",
      "        words_freqs[i, j] = float(tf)*1000/total_tf\n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#CLUSTERING: RELIES ON INITIAL SETUP OF THE CELL ABOVE\n",
      "\n",
      "#try k-means clustering.\n",
      "## TO-DO: TRY SEVERAL (~100?) DIFFERENT CLUSTERINGS AND PICK THE BEST ONE (I.E. LEAST RSS).\n",
      "import sys\n",
      "import sklearn.cluster\n",
      "from sklearn.cluster import KMeans\n",
      "\n",
      "cls = KMeans(init=\"k-means++\", n_clusters=6)\n",
      "labels = cls.fit_predict(words_freqs)\n",
      "print cls.inertia_\n",
      "for i in range(100):\n",
      "    cl_curr = KMeans(init=\"k-means++\", n_clusters=6)\n",
      "    labels = cl_curr.fit_predict(words_freqs)\n",
      "    if cls.inertia_ > cl_curr.inertia_:\n",
      "        cls = cl_curr\n",
      "    if (i%5 == 0):\n",
      "        sys.stdout.write('.')\n",
      "        \n",
      "labels = cls.predict(words_freqs)\n",
      "print \"\\n\" + str(cls.inertia_)\n",
      "print labels\n",
      "\n",
      "#have to find some way of evaluating information gain here!\n",
      "i = [0]*6\n",
      "for label in labels:\n",
      "    i[label] += 1\n",
      "print i\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1173777.79995\n",
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".\n",
        "1147079.86388"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[2 2 1 2 3 2 2 2 1 3 1 2 3 3 4 3 1 2 2 3 4 2 4 2 2 1 2 2 1 3 1 3 3 1 2 4 2\n",
        " 1 2 2 1 1 3 3 3 2 3 4 2 3 3 3 1 2 2 4 2 2 2 3 2 4 2 3 3 2 2 4 2 4 2 2 5 1\n",
        " 3 4 4 3 1 3 1 1 3 2 1 1 3 2 2 1 3 3 2 3 3 2 2 3 3 3 2 2 2 3 2 1 4 2 4 3 2\n",
        " 4 4 3 1 1 3 1 1 3 3 1 4 4 2 3 2 3 4 2 2 1 3 3 0 3 2 3 2 1 3 3 2 3 2 2 1 1\n",
        " 4 1 2 1 3 2 3 2 2 3 3 1 4 2 4 1 2 1 4 1 3 1 2 3 1 1 1 2 1 1 3 3 2 3 2 3 2\n",
        " 1 2 4 2 4 3 3 2 3 4 1 4 1 3]\n",
        "[1, 44, 67, 60, 26, 1]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/sidharth/.local/lib/python2.7/site-packages/sklearn/cluster/k_means_.py:862: RuntimeWarning: Got data type int64, converted to float to avoid overflows\n",
        "  X = self._check_test_data(X)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##### create bar graphs of the resulting word-clusters. This means finding the top 5/10 docs in the cluster and printing their\n",
      "#top words, in sorted order.\n",
      "from operator import itemgetter\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "clusters = cls.cluster_centers_\n",
      "clno = 0\n",
      "\n",
      "fig = plt.figure()\n",
      "for cluster in clusters:\n",
      "    #print cluster\n",
      "    wds = []\n",
      "    wordno = 0\n",
      "    for item in cluster:\n",
      "        if item > 5:\n",
      "            wds += [(topicwords[wordno], item)]\n",
      "            #print topicwords[wordno] + \": \" + str(item)\n",
      "        wordno += 1\n",
      "    \n",
      "    wds.sort(key = itemgetter(1), reverse = True)\n",
      "    #for wd in wds:\n",
      "    #   print wd[0] + \": \" + str(wd[1])\n",
      "    \n",
      "    ## Now, create a bar graph for the top 20 words, and repeat for all the centroids.\n",
      "    \n",
      "    cl = fig.add_subplot(2, 3, clno)\n",
      "    graphinds = range(20)\n",
      "    barvals = [int(wd[1]) for wd in wds]\n",
      "    barvals = barvals[:20]\n",
      "    barlabs = [wd[0] for wd in wds]\n",
      "    barlabs = barlabs[:20]\n",
      "    \n",
      "    #get all the points we need to create a standard deviation, and find the standard deviation.\n",
      "    clfiles = [i for i in range(len(labels)) if labels[i] == clno] #list of document indicies in given cluster\n",
      "    clvals = words_freqs[clfiles,:]\n",
      "    barsds = []\n",
      "    for val in barvals:\n",
      "        barsds += [numpy.std(clvals[:,val])] #take stdv of column.\n",
      "    \n",
      "    \n",
      "    bars = cl.bar(graphinds, barvals, yerr = barsds)\n",
      "    cl.set_xlim(-.5, 20.5)\n",
      "    cl.set_ylim(0, 100)\n",
      "    \n",
      "    cl.set_xticks(graphinds)\n",
      "    barticks = cl.set_xticklabels(barlabs)\n",
      "    plt.setp(barticks, rotation = 90)\n",
      "    clno += 1\n",
      "    #### LOOP ####\n",
      "\n",
      "\n",
      "plt.show()\n",
      "\n",
      "\n",
      "#VERY FASCINATING TO COMPARE THE RESULTS OF THIS ONE TO THE PREVIOUS ONE. IN THE OTHER ONE, THE DF STATISTIC IS\n",
      "#VERY \"TAME\", TO THE POINT WHERE IT BECOMES DIFFICULT TO DISTINGUISH BETWEEN CLUSTERS. THIS IS DEFINITELY NOT THE\n",
      "#CASE HERE... OFTEN, THERE ARE JUST ONE OR TWO WORDS THAT COMPLETELY DOMINATE THE ENTIRE SET OF REVIEWS;\n",
      "#OTHER TIMES, THE STANDARD DEVIATION IS AMAZINGLY LOW. \n",
      "\n",
      "#WITH THIS SET OF CLUSTERS, THE CLUSTERS ARE SO DIFFERENT THAT MAYBE CLASSIFICATION SHOULD BE DONE BY PERCENTAGES.\n",
      "\n",
      "#ALSO, WITH THIS CLUSTER, LARGE RELATIVE FREQUENCIES OF TWO OR THREE WORDS CAN COMPLETELY DOMINATE THE ENTIRE\n",
      "# CLUSTER. FOR EXAMPLE, THERE IS ONE CLUSTER WHERE \"SCENE, CHARACTER, AND INTERESTING\" DOMINATE EVERYTHING.\n",
      "\n",
      "#biggest distinctions seem to be between story/plot >> characters, story < characters, or story ~= characters.\n",
      "#also, there is a whole different cluster for people who use \"plot\" instead of \"story\". Is this a meaningful dist-\n",
      "#inction or not? Use of the word \"plot\" might indicate something, or it might not.\n",
      "\n",
      "#we may want to remove outliers. Also, we may want to tamp down the weight that a single word has. This could be\n",
      "#accomplished by some kind of dimensionality reduction.\n",
      "\n",
      "#ALSO, NONE OF REVIEWER 608'S REVIEWS ARE IN ENGLISH! THIS IS VERY IMPORTANT TO NOTE."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This cell is just for random printing and analysis\n",
      "#testing the validity of the calculated statistic...\n",
      "print words_freqs[0,:]\n",
      "\n",
      "f = open(\"reviewerwdscores/tf_df_reviewers8\")\n",
      "tf = []\n",
      "for line in f:\n",
      "    linearr = line.split(' ')\n",
      "    tf += [int(linearr[1])-1]\n",
      "print tf\n",
      "print sum(tf)\n",
      "print float(136)/2063"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0  6 40 13  0 44 15  4 12  4 10 14  3 10  0 13  4  0  1  6  1  8  0  1  0\n",
        "  2  0  4  2  3  9 19  0  0  4  4  0  3 15  2  5  0 13  0  9  0  3  0  8  0\n",
        "  0  3  0  0  0  0  2  4  0 65  1  0  0  0  0 10  2  4  0  1  1  0  0 17  0\n",
        "  6  5  0  0  1  1  3  0  0 10  0  0  7  0  0  1  0 18 11  0 14  1  7  0  3\n",
        "  1  0  0  0  0  1  0  0 11  0  2  0  0  0  0  0  2  1  3  1  0  0  0  0  1\n",
        "  1  0  0  0  8  0  3  0  1  1  2  0  0  0 14  0  2  1  1  1  0  0  2  0  0\n",
        "  7  2  0  5  0  0  3  0  6  0  0  0  7  0  0  1 13  1  0  1  0  2  0  0  0\n",
        "  0  1  0  0  5  0  4  0  0  0  3  2  8  0  0  0  4  0  0  0  0 27  4  3  1\n",
        "  0  1  0  0  1  0  6  8  0  0  1  4  1  0  2  0  1  0  1  0  0  0  0  0  0\n",
        "  2  2  0  1  0  0  0  0  2  7  0  0  0  0  0  0  0  0  0  0  0  0  3  3  1\n",
        "  2  2  0  0  1  9  0  7  0  0  1  0  0  0  0  2  2  1  0  3  0  0  0  0  0\n",
        "  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  5  0  0  0  0  0  2  1\n",
        "  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  8  0  0  0  0  1  2  1  6  3\n",
        "  0  1  0  0  0  0  0  0  0  3  0  0  3  0  0  0  0  0  1  0  0  1  0  0  1\n",
        "  1  0  0  2  0  0  0  0  0  0  0  3  2  3  0  1  3  0  0  0  0  0  0  0  4\n",
        "  0  2  0  0  0  0  1  2  0  0  0  0  0 10  0  0  0]\n",
        "[136, 92, 84, 56, 40, 39, 36, 31, 31, 30, 29, 29, 28, 28, 28, 28, 26, 24, 23, 22, 22, 21, 21, 21, 20, 19, 19, 18, 18, 17, 17, 17, 17, 16, 16, 16, 15, 15, 15, 14, 14, 13, 13, 13, 13, 12, 12, 11, 11, 11, 10, 10, 10, 10, 10, 10, 10, 9, 9, 9, 9, 9, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "2063\n",
        "0.0659234125061\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(len(labels)):\n",
      "    if labels[i] == 5:\n",
      "        print i\n",
      "print rev_inds[72]\n",
      "print rev_inds[134]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "72\n",
        "608\n",
        "1100\n"
       ]
      }
     ],
     "prompt_number": 6
    }
   ],
   "metadata": {}
  }
 ]
}